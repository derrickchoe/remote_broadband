{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>city</th>\n",
       "      <th>afact</th>\n",
       "      <th>place_2000_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>1067</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>1073</td>\n",
       "      <td>Adamsville</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL</td>\n",
       "      <td>1117</td>\n",
       "      <td>Alabaster</td>\n",
       "      <td>1.000</td>\n",
       "      <td>22619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AL</td>\n",
       "      <td>1095</td>\n",
       "      <td>Albertville</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AL</td>\n",
       "      <td>1123</td>\n",
       "      <td>Alexander City</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  county            city  afact place_2000_pop\n",
       "1    AL    1067       Abbeville  1.000           2987\n",
       "2    AL    1073      Adamsville  1.000           4965\n",
       "5    AL    1117       Alabaster  1.000          22619\n",
       "6    AL    1095     Albertville  1.000          17247\n",
       "7    AL    1123  Alexander City  1.000          15008"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crosswalk from place to county\n",
    "# data link: http://mcdc.missouri.edu/cgi-bin/uexplore?/data/corrlst\n",
    "\n",
    "# PROBLEM: Nashville is a (balance) instead of city. Bethesda is a CDP instead of city. \n",
    "# Check for more cases like this and somehow fix\n",
    "\n",
    "xwalk = pd.read_csv('data/place_county.csv')\n",
    "# get cities and state 2dig abbrv\n",
    "xwalk = xwalk.loc[xwalk['PlaceName'].str.endswith('city')]\n",
    "xwalk['city'] = xwalk['PlaceName'].str.split(' city').str[0]\n",
    "xwalk['state'] = xwalk['CntyName'].str[-2:]\n",
    "xwalk['county'] = xwalk['county'].astype(int)\n",
    "xwalk['place_2000_pop'] = xwalk['pop100']\n",
    "# just keep necessary columns\n",
    "xwalk = xwalk.loc[:, ['state', 'county','city', 'afact', 'place_2000_pop']]\n",
    "xwalk.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>w_avg_numproviders</th>\n",
       "      <th>avg_numproviders</th>\n",
       "      <th>median_numproviders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Akutan</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>Aleknagik</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>Allakaket</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state       city  w_avg_numproviders  avg_numproviders  median_numproviders\n",
       "0    AK     Akhiok                 3.0               3.0                  3.0\n",
       "1    AK      Akiak                 3.0               3.0                  3.0\n",
       "2    AK     Akutan                 3.0               3.0                  3.0\n",
       "3    AK  Aleknagik                 4.0               4.0                  4.0\n",
       "4    AK  Allakaket                 7.0               7.0                  7.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FCC data via Tedi-- thank you!\n",
    "fccraw = pd.read_stata('data/US_2018_county.dta')\n",
    "## frn codes don't map perfectly to provider name, but it just seems to be a renaming issue\n",
    "# x = (fcc.groupby('frn')['providername'].unique().str.len() > 1)\n",
    "# ntrue = x[x == 1]\n",
    "# fcc[fcc['frn'] == 4056248]\n",
    "\n",
    "## get number of providers by city, weighting by 2000 county population\n",
    "# number of providers per county\n",
    "fcc = fccraw.groupby('county')['frn'].nunique().reset_index()\n",
    "fcc = fcc.merge(xwalk, on = 'county')\n",
    "\n",
    "# check merge\n",
    "fcc[fcc['county'] == 47037]\n",
    "\n",
    "fcc['afact'] = fcc['afact'].astype(float)\n",
    "\n",
    "# weighted average function\n",
    "def wavg(df):\n",
    "    return((df['frn'] * df['afact']).sum().round())\n",
    "\n",
    "# weighted average number of providers by city\n",
    "fcc_gby = fcc.groupby(['state','city'])\n",
    "fcc = fcc_gby.apply(wavg).reset_index()\n",
    "fcc = fcc.rename(columns = {0: 'w_avg_numproviders'})\n",
    "fcc = fcc.merge(fcc_gby['frn'].mean().reset_index()\n",
    "                .rename(columns = {'frn': 'avg_numproviders'}), on = ['state', 'city'])\n",
    "fcc = fcc.merge(fcc_gby['frn'].median().reset_index()\n",
    "                .rename(columns = {'frn': 'median_numproviders'}), on = ['state', 'city'])\n",
    "\n",
    "fcc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs with city data: 13599\n",
      "Number of matched obs: 11233\n",
      "Unmerged GEOs\n",
      "['US-SOUTH-TN-Nashville' 'US-WEST-HI-Napili-Honokowai'\n",
      " 'US-NORTHEAST-NJ-Lakewood Township' 'US-SOUTH-VA-Tuckahoe'\n",
      " 'US-SOUTH-GA-Rex' 'US-WEST-ID-Boise' 'US-NORTHEAST-NY-Queensbury'\n",
      " 'US-NORTHEAST-PA-Huntingdon' 'US-MIDWEST-IN-Schererville'\n",
      " 'US-WEST-AZ-Marana' 'US-SOUTH-SC-Hilton Head Island'\n",
      " 'US-MIDWEST-WI-Plover' 'US-SOUTH-NC-Winston-Salem' 'US-SOUTH-AL-Shelby'\n",
      " 'US-WEST-CA-Goleta' 'US-SOUTH-LA-Sun' 'US-MIDWEST-MO-KCMO'\n",
      " 'US-SOUTH-DE-Pike Creek' 'US-WEST-AK-Anchorage'\n",
      " 'US-NORTHEAST-RI-Westerly' 'US-NORTHEAST-NY-Ballston'\n",
      " 'US-SOUTH-VA-Reston' 'US-WEST-HI-Wailuku' 'US-MIDWEST-IN-Indianapolis'\n",
      " 'US-MIDWEST-MI-Cassopolis' 'US-MIDWEST-MO-Affton' 'US-WEST-NV-Kingsbury'\n",
      " 'US-SOUTH-DE-Glasgow' 'US-MIDWEST-WI-Caledonia'\n",
      " 'US-SOUTH-TN-Collierville' 'US-WEST-AZ-Sahuarita'\n",
      " 'US-SOUTH-MD-Washington' 'US-NORTHEAST-ME-Falmouth'\n",
      " 'US-SOUTH-VA-Abingdon' 'US-MIDWEST-WI-Mount Pleasant'\n",
      " 'US-WEST-NV-Incline Village' 'US-WEST-AZ-Gilbert'\n",
      " 'US-MIDWEST-MI-Waterford Township' 'US-SOUTH-LA-Prairieville'\n",
      " 'US-WEST-HI-Kihei' 'US-SOUTH-AL-Grand Bay' 'US-WEST-NV-Carson City'\n",
      " 'US-WEST-CA-Ventura' 'US-NORTHEAST-NY-Fredonia' 'US-SOUTH-FL-Jupiter'\n",
      " 'US-NORTHEAST-PA-Lewistown' 'US-NORTHEAST-NY-Dansville'\n",
      " 'US-NORTHEAST-PA-Shippensburg' 'US-MIDWEST-IN-Westfield'\n",
      " 'US-SOUTH-TX-The Woodlands' 'US-MIDWEST-MI-Forest Hills'\n",
      " 'US-NORTHEAST-NJ-Brick Township' 'US-WEST-AZ-Buckeye' 'US-WEST-CO-Frisco'\n",
      " 'US-SOUTH-DE-Claymont' 'US-SOUTH-NC-Cary' 'US-SOUTH-SC-Edisto'\n",
      " 'US-SOUTH-DE-Brookside' 'US-SOUTH-VA-Washington' 'US-SOUTH-AL-Killen'\n",
      " 'US-WEST-CO-Windsor' 'US-SOUTH-FL-Myakka City' 'US-SOUTH-VA-Falmouth'\n",
      " 'US-WEST-HI-Honolulu' 'US-SOUTH-NC-Landis' 'US-NORTHEAST-NJ-Cherry Hill'\n",
      " 'US-NORTHEAST-PA-Bellefonte' 'US-SOUTH-FL-Davie'\n",
      " 'US-WEST-AZ-Casas Adobes' 'US-SOUTH-FL-North Naples' 'US-MIDWEST-IN-Avon'\n",
      " 'US-MIDWEST-OH-Ashville' 'US-MIDWEST-IN-Fishers' 'US-MIDWEST-IL-Oak Park'\n",
      " 'US-SOUTH-FL-Navarre' 'US-SOUTH-VA-Marion' 'US-MIDWEST-MO-Saint Charles'\n",
      " 'US-WEST-HI-Kahului' 'US-NORTHEAST-NJ-Washington Township'\n",
      " 'US-SOUTH-VA-Stuarts Draft' 'US-NORTHEAST-NY-Lake Placid'\n",
      " 'US-SOUTH-FL-The Villages' 'US-NORTHEAST-MA-Acton'\n",
      " 'US-MIDWEST-MO-Concord' 'US-WEST-AZ-Catalina Foothills'\n",
      " 'US-SOUTH-VA-Chesterfield' 'US-SOUTH-VA-Culpeper'\n",
      " 'US-NORTHEAST-PA-Mechanicsburg' 'US-SOUTH-FL-Palm City'\n",
      " 'US-SOUTH-GA-Athens' 'US-SOUTH-VA-Burke' 'US-MIDWEST-IN-Merrillville'\n",
      " 'US-SOUTH-FL-Rotonda West' 'US-NORTHEAST-MA-Plymouth'\n",
      " 'US-MIDWEST-IA-Omaha' 'US-SOUTH-NC-Kernersville' 'US-SOUTH-VA-Innsbrook'\n",
      " 'US-SOUTH-VA-Arlington' 'US-WEST-AZ-Sun City West'\n",
      " 'US-MIDWEST-MN-Saint Paul' 'US-SOUTH-LA-Ferriday'\n",
      " 'US-WEST-NV-Gardnerville Ranchos' 'US-NORTHEAST-CT-West Hartford'\n",
      " 'US-SOUTH-VA-Ashburn' 'US-NORTHEAST-NJ-Stafford Township'\n",
      " 'US-WEST-CO-Highlands Ranch' 'US-NORTHEAST-PA-Wilkes-Barre'\n",
      " 'US-NORTHEAST-NY-New Paltz' 'US-SOUTH-FL-Merritt Island'\n",
      " 'US-SOUTH-FL-Spring Hill' 'US-WEST-NM-Los Alamos' 'US-WEST-AZ-Maricopa'\n",
      " 'US-SOUTH-SC-Summerville' 'US-SOUTH-FL-Lakewood Ranch'\n",
      " 'US-SOUTH-VA-Mechanicsville' 'US-WEST-UT-Snyderville'\n",
      " 'US-MIDWEST-IL-South Elgin' 'US-NORTHEAST-NJ-Egg Harbor Township'\n",
      " 'US-WEST-AZ-Sun City' 'US-SOUTH-GA-Peachtree Corners'\n",
      " 'US-WEST-CA-El Dorado Hills' 'US-SOUTH-GA-Columbus'\n",
      " 'US-NORTHEAST-PA-Chevy Chase Heights' 'US-NORTHEAST-NJ-Edison'\n",
      " 'US-SOUTH-NC-Clemmons' 'US-SOUTH-VA-Spotsylvania Courthouse'\n",
      " 'US-SOUTH-KY-Lexington' 'US-NORTHEAST-ME-York' 'US-SOUTH-MS-Carriere'\n",
      " 'US-NORTHEAST-NJ-Galloway' 'US-NORTHEAST-NJ-East Brunswick'\n",
      " 'US-MIDWEST-MI-Meridian charter Township' 'US-MIDWEST-KS-KCMO'\n",
      " 'US-MIDWEST-WI-Cottage Grove' 'US-SOUTH-SC-Wilkinson Heights'\n",
      " 'US-NORTHEAST-NY-Massena' 'US-SOUTH-NC-River Road'\n",
      " 'US-NORTHEAST-PA-Milton' 'US-SOUTH-VA-Bon Air' 'US-MIDWEST-IL-Savoy'\n",
      " 'US-SOUTH-VA-Midlothian' 'US-NORTHEAST-NY-Saranac Lake'\n",
      " 'US-NORTHEAST-NJ-Hamilton Township' 'US-SOUTH-FL-Ruskin'\n",
      " 'US-MIDWEST-MO-Oakville' 'US-WEST-CA-Elk Grove' 'US-SOUTH-VA-Chantilly'\n",
      " 'US-NORTHEAST-NJ-Toms River' 'US-SOUTH-GA-Sandy Springs'\n",
      " 'US-WEST-AZ-Green Valley' 'US-NORTHEAST-CT-Windham'\n",
      " 'US-SOUTH-VA-Woodbridge' 'US-WEST-CO-Parker' 'US-SOUTH-VA-Glen Allen'\n",
      " 'US-SOUTH-VA-Christiansburg' 'US-MIDWEST-IL-Hoffman Estates'\n",
      " 'US-SOUTH-TN-Ooltewah' 'US-SOUTH-NC-Lewisville'\n",
      " 'US-MIDWEST-IL-Arlington Heights' 'US-NORTHEAST-CT-Newington'\n",
      " 'US-SOUTH-VA-Stafford Courthouse' 'US-MIDWEST-OH-Beckett Ridge'\n",
      " 'US-NORTHEAST-PA-Indiana' 'US-NORTHEAST-CT-Southington'\n",
      " 'US-WEST-CO-Breckenridge' 'US-NORTHEAST-CT-Cromwell'\n",
      " 'US-SOUTH-VA-Franconia' 'US-WEST-CA-Orcutt' 'US-MIDWEST-IL-Normal'\n",
      " 'US-SOUTH-GA-Augusta' 'US-SOUTH-VA-Annandale'\n",
      " 'US-NORTHEAST-PA-Monroeville' 'US-SOUTH-DE-Bear' 'US-WEST-CO-Centennial'\n",
      " 'US-MIDWEST-IN-Granger' 'US-NORTHEAST-CT-Montville'\n",
      " 'US-WEST-UT-Summit Park' 'US-SOUTH-FL-Miramar Beach'\n",
      " 'US-SOUTH-VA-Woodlake' 'US-MIDWEST-IL-Palatine' 'US-SOUTH-FL-Fruitville'\n",
      " 'US-SOUTH-AL-Chelsea' 'US-MIDWEST-IL-Lisle' 'US-NORTHEAST-NY-Getzville'\n",
      " 'US-NORTHEAST-NJ-Deptford Township' 'US-SOUTH-NC-Mooresville'\n",
      " 'US-SOUTH-MD-Elkridge' 'US-SOUTH-FL-Gulf Gate Estates' 'US-WEST-MT-Butte'\n",
      " 'US-WEST-CO-Castle Rock' 'US-MIDWEST-IL-Bourbonnais'\n",
      " 'US-NORTHEAST-CT-Farmington' 'US-SOUTH-VA-Hampden Sydney'\n",
      " 'US-SOUTH-LA-LaPlace' 'US-WEST-NV-Johnson Lane'\n",
      " 'US-MIDWEST-MI-Clinton Township' 'US-NORTHEAST-PA-State College'\n",
      " 'US-NORTHEAST-CT-Stonington' 'US-NORTHEAST-ME-Brunswick'\n",
      " 'US-SOUTH-FL-Bee Ridge' 'US-SOUTH-LA-Reserve' 'US-SOUTH-VA-Dale City'\n",
      " 'US-SOUTH-MD-Newark' 'US-MIDWEST-MO-Mehlville' 'US-NORTHEAST-PA-Ardmore'\n",
      " 'US-MIDWEST-MO-Old Jamestown' 'US-NORTHEAST-NY-Cheektowaga'\n",
      " 'US-MIDWEST-MI-Canton' 'US-WEST-CA-Alta Sierra' 'US-MIDWEST-IL-Morton'\n",
      " 'US-NORTHEAST-PA-Ross Township' 'US-WEST-WA-Spokane Valley'\n",
      " 'US-NORTHEAST-NJ-Little Egg Harbor Township' 'US-SOUTH-SC-Bamberg'\n",
      " 'US-NORTHEAST-NY-Irondequoit' 'US-WEST-AZ-Drexel Heights'\n",
      " 'US-NORTHEAST-NJ-Monroe Township'\n",
      " 'US-MIDWEST-MI-Port Huron charter Township' 'US-SOUTH-VA-Farmville'\n",
      " 'US-MIDWEST-OH-Boardman' 'US-SOUTH-GA-Johns Creek' 'US-SOUTH-VA-Chester'\n",
      " 'US-SOUTH-GA-Porterdale' 'US-SOUTH-VA-Cave Spring' 'US-SOUTH-MD-Bethesda'\n",
      " 'US-SOUTH-LA-Metairie' 'US-SOUTH-FL-Lutz' 'US-MIDWEST-WI-Waunakee'\n",
      " 'US-NORTHEAST-NJ-Secaucus' 'US-MIDWEST-IL-Schaumburg' 'US-WEST-CO-Granby'\n",
      " 'US-SOUTH-NC-Ahoskie' 'US-NORTHEAST-NJ-Fair Lawn' 'US-WEST-HI-Pukalani'\n",
      " 'US-WEST-AZ-Oro Valley' 'US-NORTHEAST-NJ-Princeton' 'US-SOUTH-GA-Tucker'\n",
      " 'US-SOUTH-VA-Patrick Springs' 'US-NORTHEAST-NJ-Parsippany-Troy Hills'\n",
      " 'US-SOUTH-FL-Sarasota Springs' 'US-SOUTH-AR-Bella Vista'\n",
      " 'US-NORTHEAST-CT-Plainville' 'US-SOUTH-MD-Potomac'\n",
      " 'US-SOUTH-NC-Oak Ridge' 'US-SOUTH-VA-Laurel' 'US-WEST-NV-Dayton'\n",
      " 'US-NORTHEAST-NJ-Franklin Township' 'US-SOUTH-SC-Brookdale'\n",
      " 'US-NORTHEAST-PA-Danville' 'US-WEST-NV-Paradise' 'US-SOUTH-FL-Pace'\n",
      " 'US-NORTHEAST-PA-Chambersburg' 'US-WEST-AZ-New River'\n",
      " 'US-MIDWEST-OH-Waverly' 'US-NORTHEAST-NJ-Roxbury Township'\n",
      " 'US-SOUTH-TX-Cypress']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>status</th>\n",
       "      <th>pub_cat</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>weight</th>\n",
       "      <th>q</th>\n",
       "      <th>response_time</th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>w_avg_numproviders</th>\n",
       "      <th>avg_numproviders</th>\n",
       "      <th>median_numproviders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100012282</td>\n",
       "      <td>2020-04-02 14:00:00</td>\n",
       "      <td>Complete</td>\n",
       "      <td>News</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>US-SOUTH-FL-Ocala</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None of the above / Not working for pay</td>\n",
       "      <td>9272</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>FL</td>\n",
       "      <td>Ocala</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1000296325</td>\n",
       "      <td>2020-04-02 03:00:00</td>\n",
       "      <td>Complete</td>\n",
       "      <td>News</td>\n",
       "      <td>Male</td>\n",
       "      <td>55-64</td>\n",
       "      <td>US-SOUTH-AL-Muscle Shoals</td>\n",
       "      <td>0.868838</td>\n",
       "      <td>I continue to commute to work</td>\n",
       "      <td>22582</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>AL</td>\n",
       "      <td>Muscle Shoals</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1000475325</td>\n",
       "      <td>2020-04-01 22:00:00</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Reference</td>\n",
       "      <td>Female</td>\n",
       "      <td>55-64</td>\n",
       "      <td>US-MIDWEST-MI</td>\n",
       "      <td>0.626525</td>\n",
       "      <td>None of the above / Not working for pay</td>\n",
       "      <td>5775</td>\n",
       "      <td>MIDWEST</td>\n",
       "      <td>MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1000492508</td>\n",
       "      <td>2020-04-02 15:00:00</td>\n",
       "      <td>Complete</td>\n",
       "      <td>News</td>\n",
       "      <td>Male</td>\n",
       "      <td>55-64</td>\n",
       "      <td>US-SOUTH-TN-Nashville</td>\n",
       "      <td>0.868838</td>\n",
       "      <td>I continue to commute to work</td>\n",
       "      <td>20659</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>TN</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1000512424</td>\n",
       "      <td>2020-04-03 14:00:00</td>\n",
       "      <td>Complete</td>\n",
       "      <td>News</td>\n",
       "      <td>Female</td>\n",
       "      <td>45-54</td>\n",
       "      <td>US-SOUTH-TX</td>\n",
       "      <td>0.966719</td>\n",
       "      <td>Used to work from home and still do</td>\n",
       "      <td>32449</td>\n",
       "      <td>SOUTH</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          id                 time    status    pub_cat   gender  \\\n",
       "0           1   100012282  2020-04-02 14:00:00  Complete       News  Unknown   \n",
       "1           2  1000296325  2020-04-02 03:00:00  Complete       News     Male   \n",
       "2           3  1000475325  2020-04-01 22:00:00  Complete  Reference   Female   \n",
       "3           4  1000492508  2020-04-02 15:00:00  Complete       News     Male   \n",
       "4           5  1000512424  2020-04-03 14:00:00  Complete       News   Female   \n",
       "\n",
       "       age                        geo    weight  \\\n",
       "0  Unknown          US-SOUTH-FL-Ocala  0.000000   \n",
       "1    55-64  US-SOUTH-AL-Muscle Shoals  0.868838   \n",
       "2    55-64              US-MIDWEST-MI  0.626525   \n",
       "3    55-64      US-SOUTH-TN-Nashville  0.868838   \n",
       "4    45-54                US-SOUTH-TX  0.966719   \n",
       "\n",
       "                                         q  response_time   region state  \\\n",
       "0  None of the above / Not working for pay           9272    SOUTH    FL   \n",
       "1            I continue to commute to work          22582    SOUTH    AL   \n",
       "2  None of the above / Not working for pay           5775  MIDWEST    MI   \n",
       "3            I continue to commute to work          20659    SOUTH    TN   \n",
       "4      Used to work from home and still do          32449    SOUTH    TX   \n",
       "\n",
       "            city  w_avg_numproviders  avg_numproviders  median_numproviders  \n",
       "0          Ocala                22.0              22.0                 22.0  \n",
       "1  Muscle Shoals                12.0              12.0                 12.0  \n",
       "2            NaN                 NaN               NaN                  NaN  \n",
       "3      Nashville                 NaN               NaN                  NaN  \n",
       "4            NaN                 NaN               NaN                  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Work from home data\n",
    "work = pd.read_csv('data/horton_data/gcs-apr5_w_states.csv')\n",
    "# city is the 4th geographic identifier in the \"geo\" column\n",
    "work['city'] = work['geo'].str.split('-').str[3]\n",
    "\n",
    "# count number of observations with city data-- 13599/25K. 54% of sample\n",
    "print(\"Number of obs with city data: {}\".format(work['city'].notnull().sum()))\n",
    "\n",
    "# count number of cities matched to fcc data\n",
    "merged = work.merge(fcc, on = ['state', 'city'], how = 'left')\n",
    "print(\"Number of matched obs: {}\".format(merged['avg_numproviders'].notnull().sum()))\n",
    "\n",
    "# unmatched cities:\n",
    "print('Unmerged GEOs')\n",
    "print(merged[(merged['avg_numproviders'].isnull()) & (merged['city'].notnull())]['geo'].unique())\n",
    "\n",
    "merged.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>avg_numproviders</th>\n",
       "      <th>median_numproviders</th>\n",
       "      <th>None of the above / Not working for pay</th>\n",
       "      <th>I continue to commute to work</th>\n",
       "      <th>Used to work from home and still do</th>\n",
       "      <th>Used to commute, now work from home</th>\n",
       "      <th>I have recently been furloughed or laid-off</th>\n",
       "      <th>Used to work from home, but now I commute</th>\n",
       "      <th>place_2000_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Anchorage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Wasilla</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabaster</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>Andalusia</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>Atmore</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state       city  avg_numproviders  median_numproviders  \\\n",
       "0    AK  Anchorage               NaN                  NaN   \n",
       "1    AK    Wasilla               5.0                  5.0   \n",
       "2    AL  Alabaster              19.0                 19.0   \n",
       "3    AL  Andalusia               9.0                  9.0   \n",
       "4    AL     Atmore              14.0                 14.0   \n",
       "\n",
       "   None of the above / Not working for pay  I continue to commute to work  \\\n",
       "0                                     12.0                            7.0   \n",
       "1                                      5.0                            0.0   \n",
       "2                                      9.0                            6.0   \n",
       "3                                      3.0                            1.0   \n",
       "4                                      3.0                            2.0   \n",
       "\n",
       "   Used to work from home and still do  Used to commute, now work from home  \\\n",
       "0                                  1.0                                  6.0   \n",
       "1                                  0.0                                  2.0   \n",
       "2                                  2.0                                  2.0   \n",
       "3                                  0.0                                  1.0   \n",
       "4                                  0.0                                  1.0   \n",
       "\n",
       "   I have recently been furloughed or laid-off  \\\n",
       "0                                          1.0   \n",
       "1                                          1.0   \n",
       "2                                          1.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   Used to work from home, but now I commute place_2000_pop  \n",
       "0                                        0.0            NaN  \n",
       "1                                        0.0           5469  \n",
       "2                                        0.0          22619  \n",
       "3                                        0.0           8794  \n",
       "4                                        0.0           7676  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get number working numbers by city\n",
    "\n",
    "# indicator for type of survey respondent\n",
    "qs = list(merged['q'].unique())\n",
    "for q in merged['q'].unique():\n",
    "    merged[q] = merged['q'] == q\n",
    "    \n",
    "# create final city-level dataset: number of providers, number of respondents not working, working remotely, etc. \n",
    "mgby = merged.groupby(['state', 'city'])\n",
    "final = mgby[['avg_numproviders', 'median_numproviders']].max().reset_index()\n",
    "final = final.merge(\n",
    "    mgby[qs].sum().reset_index(),\n",
    "    on = ['state','city'])\n",
    "\n",
    "# merge population data\n",
    "final = final.merge(xwalk[['state', 'city', 'place_2000_pop']], on = ['state', 'city'], how = 'left')\n",
    "\n",
    "final.to_csv('data/city_broadband_work.csv')\n",
    "final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>placefp</th>\n",
       "      <th>county</th>\n",
       "      <th>msacmsa</th>\n",
       "      <th>pop100</th>\n",
       "      <th>afact</th>\n",
       "      <th>PlaceName</th>\n",
       "      <th>CntyName</th>\n",
       "      <th>MetroName</th>\n",
       "      <th>Primary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>County (FIPS)</td>\n",
       "      <td>Metro Area (MSA or CMSA) 2000</td>\n",
       "      <td>Complete Count Pop 2k Census</td>\n",
       "      <td>Portion of place pop in County</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Primary County Flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>00124</td>\n",
       "      <td>01067</td>\n",
       "      <td>Non-metro</td>\n",
       "      <td>2987</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Abbeville city</td>\n",
       "      <td>Henry AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>00460</td>\n",
       "      <td>01073</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>4965</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Adamsville city</td>\n",
       "      <td>Jefferson AL</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>00484</td>\n",
       "      <td>01133</td>\n",
       "      <td>Non-metro</td>\n",
       "      <td>723</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Addison town</td>\n",
       "      <td>Winston AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>00676</td>\n",
       "      <td>01065</td>\n",
       "      <td>Non-metro</td>\n",
       "      <td>521</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Akron town</td>\n",
       "      <td>Hale AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>56</td>\n",
       "      <td>84852</td>\n",
       "      <td>56001</td>\n",
       "      <td>Non-metro</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Woods Landing-Jelm CDP</td>\n",
       "      <td>Albany WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26298</th>\n",
       "      <td>56</td>\n",
       "      <td>84925</td>\n",
       "      <td>56043</td>\n",
       "      <td>Non-metro</td>\n",
       "      <td>5250</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Worland city</td>\n",
       "      <td>Washakie WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26299</th>\n",
       "      <td>56</td>\n",
       "      <td>85015</td>\n",
       "      <td>56005</td>\n",
       "      <td>Non-metro</td>\n",
       "      <td>1347</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Wright town</td>\n",
       "      <td>Campbell WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26300</th>\n",
       "      <td>56</td>\n",
       "      <td>86665</td>\n",
       "      <td>56015</td>\n",
       "      <td>Non-metro</td>\n",
       "      <td>169</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Yoder town</td>\n",
       "      <td>Goshen WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26301</th>\n",
       "      <td>56</td>\n",
       "      <td>86737</td>\n",
       "      <td>56031</td>\n",
       "      <td>Non-metro</td>\n",
       "      <td>242</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Y-O Ranch CDP</td>\n",
       "      <td>Platte WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26302 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state placefp          county                         msacmsa  \\\n",
       "0                    County (FIPS)   Metro Area (MSA or CMSA) 2000    \n",
       "1        01   00124           01067                       Non-metro   \n",
       "2        01   00460           01073                  Birmingham, AL   \n",
       "3        01   00484           01133                       Non-metro   \n",
       "4        01   00676           01065                       Non-metro   \n",
       "...     ...     ...             ...                             ...   \n",
       "26297    56   84852           56001                       Non-metro   \n",
       "26298    56   84925           56043                       Non-metro   \n",
       "26299    56   85015           56005                       Non-metro   \n",
       "26300    56   86665           56015                       Non-metro   \n",
       "26301    56   86737           56031                       Non-metro   \n",
       "\n",
       "                              pop100                            afact  \\\n",
       "0      Complete Count Pop 2k Census   Portion of place pop in County    \n",
       "1                               2987                            1.000   \n",
       "2                               4965                            1.000   \n",
       "3                                723                            1.000   \n",
       "4                                521                            1.000   \n",
       "...                              ...                              ...   \n",
       "26297                            100                            1.000   \n",
       "26298                           5250                            1.000   \n",
       "26299                           1347                            1.000   \n",
       "26300                            169                            1.000   \n",
       "26301                            242                            1.000   \n",
       "\n",
       "                    PlaceName      CntyName MetroName              Primary  \n",
       "0                                                      Primary County Flag  \n",
       "1              Abbeville city      Henry AL       NaN                    1  \n",
       "2             Adamsville city  Jefferson AL      1000                    1  \n",
       "3                Addison town    Winston AL       NaN                    1  \n",
       "4                  Akron town       Hale AL       NaN                    1  \n",
       "...                       ...           ...       ...                  ...  \n",
       "26297  Woods Landing-Jelm CDP     Albany WY       NaN                    1  \n",
       "26298            Worland city   Washakie WY       NaN                    1  \n",
       "26299             Wright town   Campbell WY       NaN                    1  \n",
       "26300              Yoder town     Goshen WY       NaN                    1  \n",
       "26301           Y-O Ranch CDP     Platte WY       NaN                    1  \n",
       "\n",
       "[26302 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = pd.read_csv('data/place_county.csv')\n",
    "# check[check['PlaceName'].str.startswith('Nashville')]\n",
    "# check[check['PlaceName'].str.startswith('Bethesda')]\n",
    "check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
